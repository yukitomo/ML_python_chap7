{
 "metadata": {
  "name": "",
  "signature": "sha256:b63e7bcd51524ccd2c4c79c6afd98df7716631c420b6ced77d6884b4d439a8fa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#7.1 \u56de\u5e30\u3092\u7528\u3044\u3066\u7269\u4ef6\u4fa1\u683c\u3092\u4e88\u6e2c\u3059\u308b\n",
      "#\uff11\u6b21\u5143\u306e\u56de\u5e30 (feature 1\u3064\u306e\u307f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import pyplot as plt\n",
      "from sklearn.datasets import load_boston\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "boston = load_boston()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(boston.data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "506"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(boston.data[:,5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "506"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "boston.data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "array([[  6.32000000e-03,   1.80000000e+01,   2.31000000e+00, ...,\n",
        "          1.53000000e+01,   3.96900000e+02,   4.98000000e+00],\n",
        "       [  2.73100000e-02,   0.00000000e+00,   7.07000000e+00, ...,\n",
        "          1.78000000e+01,   3.96900000e+02,   9.14000000e+00],\n",
        "       [  2.72900000e-02,   0.00000000e+00,   7.07000000e+00, ...,\n",
        "          1.78000000e+01,   3.92830000e+02,   4.03000000e+00],\n",
        "       ..., \n",
        "       [  6.07600000e-02,   0.00000000e+00,   1.19300000e+01, ...,\n",
        "          2.10000000e+01,   3.96900000e+02,   5.64000000e+00],\n",
        "       [  1.09590000e-01,   0.00000000e+00,   1.19300000e+01, ...,\n",
        "          2.10000000e+01,   3.93450000e+02,   6.48000000e+00],\n",
        "       [  4.74100000e-02,   0.00000000e+00,   1.19300000e+01, ...,\n",
        "          2.10000000e+01,   3.96900000e+02,   7.88000000e+00]])"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(boston.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "506"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "boston.target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "array([ 24. ,  21.6,  34.7,  33.4,  36.2,  28.7,  22.9,  27.1,  16.5,\n",
        "        18.9,  15. ,  18.9,  21.7,  20.4,  18.2,  19.9,  23.1,  17.5,\n",
        "        20.2,  18.2,  13.6,  19.6,  15.2,  14.5,  15.6,  13.9,  16.6,\n",
        "        14.8,  18.4,  21. ,  12.7,  14.5,  13.2,  13.1,  13.5,  18.9,\n",
        "        20. ,  21. ,  24.7,  30.8,  34.9,  26.6,  25.3,  24.7,  21.2,\n",
        "        19.3,  20. ,  16.6,  14.4,  19.4,  19.7,  20.5,  25. ,  23.4,\n",
        "        18.9,  35.4,  24.7,  31.6,  23.3,  19.6,  18.7,  16. ,  22.2,\n",
        "        25. ,  33. ,  23.5,  19.4,  22. ,  17.4,  20.9,  24.2,  21.7,\n",
        "        22.8,  23.4,  24.1,  21.4,  20. ,  20.8,  21.2,  20.3,  28. ,\n",
        "        23.9,  24.8,  22.9,  23.9,  26.6,  22.5,  22.2,  23.6,  28.7,\n",
        "        22.6,  22. ,  22.9,  25. ,  20.6,  28.4,  21.4,  38.7,  43.8,\n",
        "        33.2,  27.5,  26.5,  18.6,  19.3,  20.1,  19.5,  19.5,  20.4,\n",
        "        19.8,  19.4,  21.7,  22.8,  18.8,  18.7,  18.5,  18.3,  21.2,\n",
        "        19.2,  20.4,  19.3,  22. ,  20.3,  20.5,  17.3,  18.8,  21.4,\n",
        "        15.7,  16.2,  18. ,  14.3,  19.2,  19.6,  23. ,  18.4,  15.6,\n",
        "        18.1,  17.4,  17.1,  13.3,  17.8,  14. ,  14.4,  13.4,  15.6,\n",
        "        11.8,  13.8,  15.6,  14.6,  17.8,  15.4,  21.5,  19.6,  15.3,\n",
        "        19.4,  17. ,  15.6,  13.1,  41.3,  24.3,  23.3,  27. ,  50. ,\n",
        "        50. ,  50. ,  22.7,  25. ,  50. ,  23.8,  23.8,  22.3,  17.4,\n",
        "        19.1,  23.1,  23.6,  22.6,  29.4,  23.2,  24.6,  29.9,  37.2,\n",
        "        39.8,  36.2,  37.9,  32.5,  26.4,  29.6,  50. ,  32. ,  29.8,\n",
        "        34.9,  37. ,  30.5,  36.4,  31.1,  29.1,  50. ,  33.3,  30.3,\n",
        "        34.6,  34.9,  32.9,  24.1,  42.3,  48.5,  50. ,  22.6,  24.4,\n",
        "        22.5,  24.4,  20. ,  21.7,  19.3,  22.4,  28.1,  23.7,  25. ,\n",
        "        23.3,  28.7,  21.5,  23. ,  26.7,  21.7,  27.5,  30.1,  44.8,\n",
        "        50. ,  37.6,  31.6,  46.7,  31.5,  24.3,  31.7,  41.7,  48.3,\n",
        "        29. ,  24. ,  25.1,  31.5,  23.7,  23.3,  22. ,  20.1,  22.2,\n",
        "        23.7,  17.6,  18.5,  24.3,  20.5,  24.5,  26.2,  24.4,  24.8,\n",
        "        29.6,  42.8,  21.9,  20.9,  44. ,  50. ,  36. ,  30.1,  33.8,\n",
        "        43.1,  48.8,  31. ,  36.5,  22.8,  30.7,  50. ,  43.5,  20.7,\n",
        "        21.1,  25.2,  24.4,  35.2,  32.4,  32. ,  33.2,  33.1,  29.1,\n",
        "        35.1,  45.4,  35.4,  46. ,  50. ,  32.2,  22. ,  20.1,  23.2,\n",
        "        22.3,  24.8,  28.5,  37.3,  27.9,  23.9,  21.7,  28.6,  27.1,\n",
        "        20.3,  22.5,  29. ,  24.8,  22. ,  26.4,  33.1,  36.1,  28.4,\n",
        "        33.4,  28.2,  22.8,  20.3,  16.1,  22.1,  19.4,  21.6,  23.8,\n",
        "        16.2,  17.8,  19.8,  23.1,  21. ,  23.8,  23.1,  20.4,  18.5,\n",
        "        25. ,  24.6,  23. ,  22.2,  19.3,  22.6,  19.8,  17.1,  19.4,\n",
        "        22.2,  20.7,  21.1,  19.5,  18.5,  20.6,  19. ,  18.7,  32.7,\n",
        "        16.5,  23.9,  31.2,  17.5,  17.2,  23.1,  24.5,  26.6,  22.9,\n",
        "        24.1,  18.6,  30.1,  18.2,  20.6,  17.8,  21.7,  22.7,  22.6,\n",
        "        25. ,  19.9,  20.8,  16.8,  21.9,  27.5,  21.9,  23.1,  50. ,\n",
        "        50. ,  50. ,  50. ,  50. ,  13.8,  13.8,  15. ,  13.9,  13.3,\n",
        "        13.1,  10.2,  10.4,  10.9,  11.3,  12.3,   8.8,   7.2,  10.5,\n",
        "         7.4,  10.2,  11.5,  15.1,  23.2,   9.7,  13.8,  12.7,  13.1,\n",
        "        12.5,   8.5,   5. ,   6.3,   5.6,   7.2,  12.1,   8.3,   8.5,\n",
        "         5. ,  11.9,  27.9,  17.2,  27.5,  15. ,  17.2,  17.9,  16.3,\n",
        "         7. ,   7.2,   7.5,  10.4,   8.8,   8.4,  16.7,  14.2,  20.8,\n",
        "        13.4,  11.7,   8.3,  10.2,  10.9,  11. ,   9.5,  14.5,  14.1,\n",
        "        16.1,  14.3,  11.7,  13.4,   9.6,   8.7,   8.4,  12.8,  10.5,\n",
        "        17.1,  18.4,  15.4,  10.8,  11.8,  14.9,  12.6,  14.1,  13. ,\n",
        "        13.4,  15.2,  16.1,  17.8,  14.9,  14.1,  12.7,  13.5,  14.9,\n",
        "        20. ,  16.4,  17.7,  19.5,  20.2,  21.4,  19.9,  19. ,  19.1,\n",
        "        19.1,  20.1,  19.9,  19.6,  23.2,  29.8,  13.8,  13.3,  16.7,\n",
        "        12. ,  14.6,  21.4,  23. ,  23.7,  25. ,  21.8,  20.6,  21.2,\n",
        "        19.1,  20.6,  15.2,   7. ,   8.1,  13.6,  20.1,  21.8,  24.5,\n",
        "        23.1,  19.7,  18.3,  21.2,  17.5,  16.8,  22.4,  20.6,  23.9,\n",
        "        22. ,  11.9])"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(boston.data[:,5], boston.target, color='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "<matplotlib.collections.PathCollection at 0x10d967710>"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#single feature \u306e\u56de\u5e30"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = boston.data[:,5]\n",
      "x = np.array([[v] for v in x])  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "array([[ 6.575],\n",
        "       [ 6.421],\n",
        "       [ 7.185],\n",
        "       [ 6.998],\n",
        "       [ 7.147],\n",
        "       [ 6.43 ],\n",
        "       [ 6.012],\n",
        "       [ 6.172],\n",
        "       [ 5.631],\n",
        "       [ 6.004],\n",
        "       [ 6.377],\n",
        "       [ 6.009],\n",
        "       [ 5.889],\n",
        "       [ 5.949],\n",
        "       [ 6.096],\n",
        "       [ 5.834],\n",
        "       [ 5.935],\n",
        "       [ 5.99 ],\n",
        "       [ 5.456],\n",
        "       [ 5.727],\n",
        "       [ 5.57 ],\n",
        "       [ 5.965],\n",
        "       [ 6.142],\n",
        "       [ 5.813],\n",
        "       [ 5.924],\n",
        "       [ 5.599],\n",
        "       [ 5.813],\n",
        "       [ 6.047],\n",
        "       [ 6.495],\n",
        "       [ 6.674],\n",
        "       [ 5.713],\n",
        "       [ 6.072],\n",
        "       [ 5.95 ],\n",
        "       [ 5.701],\n",
        "       [ 6.096],\n",
        "       [ 5.933],\n",
        "       [ 5.841],\n",
        "       [ 5.85 ],\n",
        "       [ 5.966],\n",
        "       [ 6.595],\n",
        "       [ 7.024],\n",
        "       [ 6.77 ],\n",
        "       [ 6.169],\n",
        "       [ 6.211],\n",
        "       [ 6.069],\n",
        "       [ 5.682],\n",
        "       [ 5.786],\n",
        "       [ 6.03 ],\n",
        "       [ 5.399],\n",
        "       [ 5.602],\n",
        "       [ 5.963],\n",
        "       [ 6.115],\n",
        "       [ 6.511],\n",
        "       [ 5.998],\n",
        "       [ 5.888],\n",
        "       [ 7.249],\n",
        "       [ 6.383],\n",
        "       [ 6.816],\n",
        "       [ 6.145],\n",
        "       [ 5.927],\n",
        "       [ 5.741],\n",
        "       [ 5.966],\n",
        "       [ 6.456],\n",
        "       [ 6.762],\n",
        "       [ 7.104],\n",
        "       [ 6.29 ],\n",
        "       [ 5.787],\n",
        "       [ 5.878],\n",
        "       [ 5.594],\n",
        "       [ 5.885],\n",
        "       [ 6.417],\n",
        "       [ 5.961],\n",
        "       [ 6.065],\n",
        "       [ 6.245],\n",
        "       [ 6.273],\n",
        "       [ 6.286],\n",
        "       [ 6.279],\n",
        "       [ 6.14 ],\n",
        "       [ 6.232],\n",
        "       [ 5.874],\n",
        "       [ 6.727],\n",
        "       [ 6.619],\n",
        "       [ 6.302],\n",
        "       [ 6.167],\n",
        "       [ 6.389],\n",
        "       [ 6.63 ],\n",
        "       [ 6.015],\n",
        "       [ 6.121],\n",
        "       [ 7.007],\n",
        "       [ 7.079],\n",
        "       [ 6.417],\n",
        "       [ 6.405],\n",
        "       [ 6.442],\n",
        "       [ 6.211],\n",
        "       [ 6.249],\n",
        "       [ 6.625],\n",
        "       [ 6.163],\n",
        "       [ 8.069],\n",
        "       [ 7.82 ],\n",
        "       [ 7.416],\n",
        "       [ 6.727],\n",
        "       [ 6.781],\n",
        "       [ 6.405],\n",
        "       [ 6.137],\n",
        "       [ 6.167],\n",
        "       [ 5.851],\n",
        "       [ 5.836],\n",
        "       [ 6.127],\n",
        "       [ 6.474],\n",
        "       [ 6.229],\n",
        "       [ 6.195],\n",
        "       [ 6.715],\n",
        "       [ 5.913],\n",
        "       [ 6.092],\n",
        "       [ 6.254],\n",
        "       [ 5.928],\n",
        "       [ 6.176],\n",
        "       [ 6.021],\n",
        "       [ 5.872],\n",
        "       [ 5.731],\n",
        "       [ 5.87 ],\n",
        "       [ 6.004],\n",
        "       [ 5.961],\n",
        "       [ 5.856],\n",
        "       [ 5.879],\n",
        "       [ 5.986],\n",
        "       [ 5.613],\n",
        "       [ 5.693],\n",
        "       [ 6.431],\n",
        "       [ 5.637],\n",
        "       [ 6.458],\n",
        "       [ 6.326],\n",
        "       [ 6.372],\n",
        "       [ 5.822],\n",
        "       [ 5.757],\n",
        "       [ 6.335],\n",
        "       [ 5.942],\n",
        "       [ 6.454],\n",
        "       [ 5.857],\n",
        "       [ 6.151],\n",
        "       [ 6.174],\n",
        "       [ 5.019],\n",
        "       [ 5.403],\n",
        "       [ 5.468],\n",
        "       [ 4.903],\n",
        "       [ 6.13 ],\n",
        "       [ 5.628],\n",
        "       [ 4.926],\n",
        "       [ 5.186],\n",
        "       [ 5.597],\n",
        "       [ 6.122],\n",
        "       [ 5.404],\n",
        "       [ 5.012],\n",
        "       [ 5.709],\n",
        "       [ 6.129],\n",
        "       [ 6.152],\n",
        "       [ 5.272],\n",
        "       [ 6.943],\n",
        "       [ 6.066],\n",
        "       [ 6.51 ],\n",
        "       [ 6.25 ],\n",
        "       [ 7.489],\n",
        "       [ 7.802],\n",
        "       [ 8.375],\n",
        "       [ 5.854],\n",
        "       [ 6.101],\n",
        "       [ 7.929],\n",
        "       [ 5.877],\n",
        "       [ 6.319],\n",
        "       [ 6.402],\n",
        "       [ 5.875],\n",
        "       [ 5.88 ],\n",
        "       [ 5.572],\n",
        "       [ 6.416],\n",
        "       [ 5.859],\n",
        "       [ 6.546],\n",
        "       [ 6.02 ],\n",
        "       [ 6.315],\n",
        "       [ 6.86 ],\n",
        "       [ 6.98 ],\n",
        "       [ 7.765],\n",
        "       [ 6.144],\n",
        "       [ 7.155],\n",
        "       [ 6.563],\n",
        "       [ 5.604],\n",
        "       [ 6.153],\n",
        "       [ 7.831],\n",
        "       [ 6.782],\n",
        "       [ 6.556],\n",
        "       [ 7.185],\n",
        "       [ 6.951],\n",
        "       [ 6.739],\n",
        "       [ 7.178],\n",
        "       [ 6.8  ],\n",
        "       [ 6.604],\n",
        "       [ 7.875],\n",
        "       [ 7.287],\n",
        "       [ 7.107],\n",
        "       [ 7.274],\n",
        "       [ 6.975],\n",
        "       [ 7.135],\n",
        "       [ 6.162],\n",
        "       [ 7.61 ],\n",
        "       [ 7.853],\n",
        "       [ 8.034],\n",
        "       [ 5.891],\n",
        "       [ 6.326],\n",
        "       [ 5.783],\n",
        "       [ 6.064],\n",
        "       [ 5.344],\n",
        "       [ 5.96 ],\n",
        "       [ 5.404],\n",
        "       [ 5.807],\n",
        "       [ 6.375],\n",
        "       [ 5.412],\n",
        "       [ 6.182],\n",
        "       [ 5.888],\n",
        "       [ 6.642],\n",
        "       [ 5.951],\n",
        "       [ 6.373],\n",
        "       [ 6.951],\n",
        "       [ 6.164],\n",
        "       [ 6.879],\n",
        "       [ 6.618],\n",
        "       [ 8.266],\n",
        "       [ 8.725],\n",
        "       [ 8.04 ],\n",
        "       [ 7.163],\n",
        "       [ 7.686],\n",
        "       [ 6.552],\n",
        "       [ 5.981],\n",
        "       [ 7.412],\n",
        "       [ 8.337],\n",
        "       [ 8.247],\n",
        "       [ 6.726],\n",
        "       [ 6.086],\n",
        "       [ 6.631],\n",
        "       [ 7.358],\n",
        "       [ 6.481],\n",
        "       [ 6.606],\n",
        "       [ 6.897],\n",
        "       [ 6.095],\n",
        "       [ 6.358],\n",
        "       [ 6.393],\n",
        "       [ 5.593],\n",
        "       [ 5.605],\n",
        "       [ 6.108],\n",
        "       [ 6.226],\n",
        "       [ 6.433],\n",
        "       [ 6.718],\n",
        "       [ 6.487],\n",
        "       [ 6.438],\n",
        "       [ 6.957],\n",
        "       [ 8.259],\n",
        "       [ 6.108],\n",
        "       [ 5.876],\n",
        "       [ 7.454],\n",
        "       [ 8.704],\n",
        "       [ 7.333],\n",
        "       [ 6.842],\n",
        "       [ 7.203],\n",
        "       [ 7.52 ],\n",
        "       [ 8.398],\n",
        "       [ 7.327],\n",
        "       [ 7.206],\n",
        "       [ 5.56 ],\n",
        "       [ 7.014],\n",
        "       [ 8.297],\n",
        "       [ 7.47 ],\n",
        "       [ 5.92 ],\n",
        "       [ 5.856],\n",
        "       [ 6.24 ],\n",
        "       [ 6.538],\n",
        "       [ 7.691],\n",
        "       [ 6.758],\n",
        "       [ 6.854],\n",
        "       [ 7.267],\n",
        "       [ 6.826],\n",
        "       [ 6.482],\n",
        "       [ 6.812],\n",
        "       [ 7.82 ],\n",
        "       [ 6.968],\n",
        "       [ 7.645],\n",
        "       [ 7.923],\n",
        "       [ 7.088],\n",
        "       [ 6.453],\n",
        "       [ 6.23 ],\n",
        "       [ 6.209],\n",
        "       [ 6.315],\n",
        "       [ 6.565],\n",
        "       [ 6.861],\n",
        "       [ 7.148],\n",
        "       [ 6.63 ],\n",
        "       [ 6.127],\n",
        "       [ 6.009],\n",
        "       [ 6.678],\n",
        "       [ 6.549],\n",
        "       [ 5.79 ],\n",
        "       [ 6.345],\n",
        "       [ 7.041],\n",
        "       [ 6.871],\n",
        "       [ 6.59 ],\n",
        "       [ 6.495],\n",
        "       [ 6.982],\n",
        "       [ 7.236],\n",
        "       [ 6.616],\n",
        "       [ 7.42 ],\n",
        "       [ 6.849],\n",
        "       [ 6.635],\n",
        "       [ 5.972],\n",
        "       [ 4.973],\n",
        "       [ 6.122],\n",
        "       [ 6.023],\n",
        "       [ 6.266],\n",
        "       [ 6.567],\n",
        "       [ 5.705],\n",
        "       [ 5.914],\n",
        "       [ 5.782],\n",
        "       [ 6.382],\n",
        "       [ 6.113],\n",
        "       [ 6.426],\n",
        "       [ 6.376],\n",
        "       [ 6.041],\n",
        "       [ 5.708],\n",
        "       [ 6.415],\n",
        "       [ 6.431],\n",
        "       [ 6.312],\n",
        "       [ 6.083],\n",
        "       [ 5.868],\n",
        "       [ 6.333],\n",
        "       [ 6.144],\n",
        "       [ 5.706],\n",
        "       [ 6.031],\n",
        "       [ 6.316],\n",
        "       [ 6.31 ],\n",
        "       [ 6.037],\n",
        "       [ 5.869],\n",
        "       [ 5.895],\n",
        "       [ 6.059],\n",
        "       [ 5.985],\n",
        "       [ 5.968],\n",
        "       [ 7.241],\n",
        "       [ 6.54 ],\n",
        "       [ 6.696],\n",
        "       [ 6.874],\n",
        "       [ 6.014],\n",
        "       [ 5.898],\n",
        "       [ 6.516],\n",
        "       [ 6.635],\n",
        "       [ 6.939],\n",
        "       [ 6.49 ],\n",
        "       [ 6.579],\n",
        "       [ 5.884],\n",
        "       [ 6.728],\n",
        "       [ 5.663],\n",
        "       [ 5.936],\n",
        "       [ 6.212],\n",
        "       [ 6.395],\n",
        "       [ 6.127],\n",
        "       [ 6.112],\n",
        "       [ 6.398],\n",
        "       [ 6.251],\n",
        "       [ 5.362],\n",
        "       [ 5.803],\n",
        "       [ 8.78 ],\n",
        "       [ 3.561],\n",
        "       [ 4.963],\n",
        "       [ 3.863],\n",
        "       [ 4.97 ],\n",
        "       [ 6.683],\n",
        "       [ 7.016],\n",
        "       [ 6.216],\n",
        "       [ 5.875],\n",
        "       [ 4.906],\n",
        "       [ 4.138],\n",
        "       [ 7.313],\n",
        "       [ 6.649],\n",
        "       [ 6.794],\n",
        "       [ 6.38 ],\n",
        "       [ 6.223],\n",
        "       [ 6.968],\n",
        "       [ 6.545],\n",
        "       [ 5.536],\n",
        "       [ 5.52 ],\n",
        "       [ 4.368],\n",
        "       [ 5.277],\n",
        "       [ 4.652],\n",
        "       [ 5.   ],\n",
        "       [ 4.88 ],\n",
        "       [ 5.39 ],\n",
        "       [ 5.713],\n",
        "       [ 6.051],\n",
        "       [ 5.036],\n",
        "       [ 6.193],\n",
        "       [ 5.887],\n",
        "       [ 6.471],\n",
        "       [ 6.405],\n",
        "       [ 5.747],\n",
        "       [ 5.453],\n",
        "       [ 5.852],\n",
        "       [ 5.987],\n",
        "       [ 6.343],\n",
        "       [ 6.404],\n",
        "       [ 5.349],\n",
        "       [ 5.531],\n",
        "       [ 5.683],\n",
        "       [ 4.138],\n",
        "       [ 5.608],\n",
        "       [ 5.617],\n",
        "       [ 6.852],\n",
        "       [ 5.757],\n",
        "       [ 6.657],\n",
        "       [ 4.628],\n",
        "       [ 5.155],\n",
        "       [ 4.519],\n",
        "       [ 6.434],\n",
        "       [ 6.782],\n",
        "       [ 5.304],\n",
        "       [ 5.957],\n",
        "       [ 6.824],\n",
        "       [ 6.411],\n",
        "       [ 6.006],\n",
        "       [ 5.648],\n",
        "       [ 6.103],\n",
        "       [ 5.565],\n",
        "       [ 5.896],\n",
        "       [ 5.837],\n",
        "       [ 6.202],\n",
        "       [ 6.193],\n",
        "       [ 6.38 ],\n",
        "       [ 6.348],\n",
        "       [ 6.833],\n",
        "       [ 6.425],\n",
        "       [ 6.436],\n",
        "       [ 6.208],\n",
        "       [ 6.629],\n",
        "       [ 6.461],\n",
        "       [ 6.152],\n",
        "       [ 5.935],\n",
        "       [ 5.627],\n",
        "       [ 5.818],\n",
        "       [ 6.406],\n",
        "       [ 6.219],\n",
        "       [ 6.485],\n",
        "       [ 5.854],\n",
        "       [ 6.459],\n",
        "       [ 6.341],\n",
        "       [ 6.251],\n",
        "       [ 6.185],\n",
        "       [ 6.417],\n",
        "       [ 6.749],\n",
        "       [ 6.655],\n",
        "       [ 6.297],\n",
        "       [ 7.393],\n",
        "       [ 6.728],\n",
        "       [ 6.525],\n",
        "       [ 5.976],\n",
        "       [ 5.936],\n",
        "       [ 6.301],\n",
        "       [ 6.081],\n",
        "       [ 6.701],\n",
        "       [ 6.376],\n",
        "       [ 6.317],\n",
        "       [ 6.513],\n",
        "       [ 6.209],\n",
        "       [ 5.759],\n",
        "       [ 5.952],\n",
        "       [ 6.003],\n",
        "       [ 5.926],\n",
        "       [ 5.713],\n",
        "       [ 6.167],\n",
        "       [ 6.229],\n",
        "       [ 6.437],\n",
        "       [ 6.98 ],\n",
        "       [ 5.427],\n",
        "       [ 6.162],\n",
        "       [ 6.484],\n",
        "       [ 5.304],\n",
        "       [ 6.185],\n",
        "       [ 6.229],\n",
        "       [ 6.242],\n",
        "       [ 6.75 ],\n",
        "       [ 7.061],\n",
        "       [ 5.762],\n",
        "       [ 5.871],\n",
        "       [ 6.312],\n",
        "       [ 6.114],\n",
        "       [ 5.905],\n",
        "       [ 5.454],\n",
        "       [ 5.414],\n",
        "       [ 5.093],\n",
        "       [ 5.983],\n",
        "       [ 5.983],\n",
        "       [ 5.707],\n",
        "       [ 5.926],\n",
        "       [ 5.67 ],\n",
        "       [ 5.39 ],\n",
        "       [ 5.794],\n",
        "       [ 6.019],\n",
        "       [ 5.569],\n",
        "       [ 6.027],\n",
        "       [ 6.593],\n",
        "       [ 6.12 ],\n",
        "       [ 6.976],\n",
        "       [ 6.794],\n",
        "       [ 6.03 ]])"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = boston.target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "array([ 24. ,  21.6,  34.7,  33.4,  36.2,  28.7,  22.9,  27.1,  16.5,\n",
        "        18.9,  15. ,  18.9,  21.7,  20.4,  18.2,  19.9,  23.1,  17.5,\n",
        "        20.2,  18.2,  13.6,  19.6,  15.2,  14.5,  15.6,  13.9,  16.6,\n",
        "        14.8,  18.4,  21. ,  12.7,  14.5,  13.2,  13.1,  13.5,  18.9,\n",
        "        20. ,  21. ,  24.7,  30.8,  34.9,  26.6,  25.3,  24.7,  21.2,\n",
        "        19.3,  20. ,  16.6,  14.4,  19.4,  19.7,  20.5,  25. ,  23.4,\n",
        "        18.9,  35.4,  24.7,  31.6,  23.3,  19.6,  18.7,  16. ,  22.2,\n",
        "        25. ,  33. ,  23.5,  19.4,  22. ,  17.4,  20.9,  24.2,  21.7,\n",
        "        22.8,  23.4,  24.1,  21.4,  20. ,  20.8,  21.2,  20.3,  28. ,\n",
        "        23.9,  24.8,  22.9,  23.9,  26.6,  22.5,  22.2,  23.6,  28.7,\n",
        "        22.6,  22. ,  22.9,  25. ,  20.6,  28.4,  21.4,  38.7,  43.8,\n",
        "        33.2,  27.5,  26.5,  18.6,  19.3,  20.1,  19.5,  19.5,  20.4,\n",
        "        19.8,  19.4,  21.7,  22.8,  18.8,  18.7,  18.5,  18.3,  21.2,\n",
        "        19.2,  20.4,  19.3,  22. ,  20.3,  20.5,  17.3,  18.8,  21.4,\n",
        "        15.7,  16.2,  18. ,  14.3,  19.2,  19.6,  23. ,  18.4,  15.6,\n",
        "        18.1,  17.4,  17.1,  13.3,  17.8,  14. ,  14.4,  13.4,  15.6,\n",
        "        11.8,  13.8,  15.6,  14.6,  17.8,  15.4,  21.5,  19.6,  15.3,\n",
        "        19.4,  17. ,  15.6,  13.1,  41.3,  24.3,  23.3,  27. ,  50. ,\n",
        "        50. ,  50. ,  22.7,  25. ,  50. ,  23.8,  23.8,  22.3,  17.4,\n",
        "        19.1,  23.1,  23.6,  22.6,  29.4,  23.2,  24.6,  29.9,  37.2,\n",
        "        39.8,  36.2,  37.9,  32.5,  26.4,  29.6,  50. ,  32. ,  29.8,\n",
        "        34.9,  37. ,  30.5,  36.4,  31.1,  29.1,  50. ,  33.3,  30.3,\n",
        "        34.6,  34.9,  32.9,  24.1,  42.3,  48.5,  50. ,  22.6,  24.4,\n",
        "        22.5,  24.4,  20. ,  21.7,  19.3,  22.4,  28.1,  23.7,  25. ,\n",
        "        23.3,  28.7,  21.5,  23. ,  26.7,  21.7,  27.5,  30.1,  44.8,\n",
        "        50. ,  37.6,  31.6,  46.7,  31.5,  24.3,  31.7,  41.7,  48.3,\n",
        "        29. ,  24. ,  25.1,  31.5,  23.7,  23.3,  22. ,  20.1,  22.2,\n",
        "        23.7,  17.6,  18.5,  24.3,  20.5,  24.5,  26.2,  24.4,  24.8,\n",
        "        29.6,  42.8,  21.9,  20.9,  44. ,  50. ,  36. ,  30.1,  33.8,\n",
        "        43.1,  48.8,  31. ,  36.5,  22.8,  30.7,  50. ,  43.5,  20.7,\n",
        "        21.1,  25.2,  24.4,  35.2,  32.4,  32. ,  33.2,  33.1,  29.1,\n",
        "        35.1,  45.4,  35.4,  46. ,  50. ,  32.2,  22. ,  20.1,  23.2,\n",
        "        22.3,  24.8,  28.5,  37.3,  27.9,  23.9,  21.7,  28.6,  27.1,\n",
        "        20.3,  22.5,  29. ,  24.8,  22. ,  26.4,  33.1,  36.1,  28.4,\n",
        "        33.4,  28.2,  22.8,  20.3,  16.1,  22.1,  19.4,  21.6,  23.8,\n",
        "        16.2,  17.8,  19.8,  23.1,  21. ,  23.8,  23.1,  20.4,  18.5,\n",
        "        25. ,  24.6,  23. ,  22.2,  19.3,  22.6,  19.8,  17.1,  19.4,\n",
        "        22.2,  20.7,  21.1,  19.5,  18.5,  20.6,  19. ,  18.7,  32.7,\n",
        "        16.5,  23.9,  31.2,  17.5,  17.2,  23.1,  24.5,  26.6,  22.9,\n",
        "        24.1,  18.6,  30.1,  18.2,  20.6,  17.8,  21.7,  22.7,  22.6,\n",
        "        25. ,  19.9,  20.8,  16.8,  21.9,  27.5,  21.9,  23.1,  50. ,\n",
        "        50. ,  50. ,  50. ,  50. ,  13.8,  13.8,  15. ,  13.9,  13.3,\n",
        "        13.1,  10.2,  10.4,  10.9,  11.3,  12.3,   8.8,   7.2,  10.5,\n",
        "         7.4,  10.2,  11.5,  15.1,  23.2,   9.7,  13.8,  12.7,  13.1,\n",
        "        12.5,   8.5,   5. ,   6.3,   5.6,   7.2,  12.1,   8.3,   8.5,\n",
        "         5. ,  11.9,  27.9,  17.2,  27.5,  15. ,  17.2,  17.9,  16.3,\n",
        "         7. ,   7.2,   7.5,  10.4,   8.8,   8.4,  16.7,  14.2,  20.8,\n",
        "        13.4,  11.7,   8.3,  10.2,  10.9,  11. ,   9.5,  14.5,  14.1,\n",
        "        16.1,  14.3,  11.7,  13.4,   9.6,   8.7,   8.4,  12.8,  10.5,\n",
        "        17.1,  18.4,  15.4,  10.8,  11.8,  14.9,  12.6,  14.1,  13. ,\n",
        "        13.4,  15.2,  16.1,  17.8,  14.9,  14.1,  12.7,  13.5,  14.9,\n",
        "        20. ,  16.4,  17.7,  19.5,  20.2,  21.4,  19.9,  19. ,  19.1,\n",
        "        19.1,  20.1,  19.9,  19.6,  23.2,  29.8,  13.8,  13.3,  16.7,\n",
        "        12. ,  14.6,  21.4,  23. ,  23.7,  25. ,  21.8,  20.6,  21.2,\n",
        "        19.1,  20.6,  15.2,   7. ,   8.1,  13.6,  20.1,  21.8,  24.5,\n",
        "        23.1,  19.7,  18.3,  21.2,  17.5,  16.8,  22.4,  20.6,  23.9,\n",
        "        22. ,  11.9])"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u50be\u304d\u306e\u8a08\u7b97\n",
      "slope,total_error ,_,_ = np.linalg.lstsq(x,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "slope"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "array([ 3.6533504])"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total_error"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "array([ 29555.78152864])"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rmse = np.sqrt(total_error[0]/len(x))\n",
      "print('RMSE on training: {}'.format(rmse))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE on training: 7.64268509309\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#single feature + bias"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = boston.data[:,5]\n",
      "x = np.array([[v,1] for v in x])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "array([[ 6.575,  1.   ],\n",
        "       [ 6.421,  1.   ],\n",
        "       [ 7.185,  1.   ],\n",
        "       ..., \n",
        "       [ 6.976,  1.   ],\n",
        "       [ 6.794,  1.   ],\n",
        "       [ 6.03 ,  1.   ]])"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = boston.target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "array([ 24. ,  21.6,  34.7,  33.4,  36.2,  28.7,  22.9,  27.1,  16.5,\n",
        "        18.9,  15. ,  18.9,  21.7,  20.4,  18.2,  19.9,  23.1,  17.5,\n",
        "        20.2,  18.2,  13.6,  19.6,  15.2,  14.5,  15.6,  13.9,  16.6,\n",
        "        14.8,  18.4,  21. ,  12.7,  14.5,  13.2,  13.1,  13.5,  18.9,\n",
        "        20. ,  21. ,  24.7,  30.8,  34.9,  26.6,  25.3,  24.7,  21.2,\n",
        "        19.3,  20. ,  16.6,  14.4,  19.4,  19.7,  20.5,  25. ,  23.4,\n",
        "        18.9,  35.4,  24.7,  31.6,  23.3,  19.6,  18.7,  16. ,  22.2,\n",
        "        25. ,  33. ,  23.5,  19.4,  22. ,  17.4,  20.9,  24.2,  21.7,\n",
        "        22.8,  23.4,  24.1,  21.4,  20. ,  20.8,  21.2,  20.3,  28. ,\n",
        "        23.9,  24.8,  22.9,  23.9,  26.6,  22.5,  22.2,  23.6,  28.7,\n",
        "        22.6,  22. ,  22.9,  25. ,  20.6,  28.4,  21.4,  38.7,  43.8,\n",
        "        33.2,  27.5,  26.5,  18.6,  19.3,  20.1,  19.5,  19.5,  20.4,\n",
        "        19.8,  19.4,  21.7,  22.8,  18.8,  18.7,  18.5,  18.3,  21.2,\n",
        "        19.2,  20.4,  19.3,  22. ,  20.3,  20.5,  17.3,  18.8,  21.4,\n",
        "        15.7,  16.2,  18. ,  14.3,  19.2,  19.6,  23. ,  18.4,  15.6,\n",
        "        18.1,  17.4,  17.1,  13.3,  17.8,  14. ,  14.4,  13.4,  15.6,\n",
        "        11.8,  13.8,  15.6,  14.6,  17.8,  15.4,  21.5,  19.6,  15.3,\n",
        "        19.4,  17. ,  15.6,  13.1,  41.3,  24.3,  23.3,  27. ,  50. ,\n",
        "        50. ,  50. ,  22.7,  25. ,  50. ,  23.8,  23.8,  22.3,  17.4,\n",
        "        19.1,  23.1,  23.6,  22.6,  29.4,  23.2,  24.6,  29.9,  37.2,\n",
        "        39.8,  36.2,  37.9,  32.5,  26.4,  29.6,  50. ,  32. ,  29.8,\n",
        "        34.9,  37. ,  30.5,  36.4,  31.1,  29.1,  50. ,  33.3,  30.3,\n",
        "        34.6,  34.9,  32.9,  24.1,  42.3,  48.5,  50. ,  22.6,  24.4,\n",
        "        22.5,  24.4,  20. ,  21.7,  19.3,  22.4,  28.1,  23.7,  25. ,\n",
        "        23.3,  28.7,  21.5,  23. ,  26.7,  21.7,  27.5,  30.1,  44.8,\n",
        "        50. ,  37.6,  31.6,  46.7,  31.5,  24.3,  31.7,  41.7,  48.3,\n",
        "        29. ,  24. ,  25.1,  31.5,  23.7,  23.3,  22. ,  20.1,  22.2,\n",
        "        23.7,  17.6,  18.5,  24.3,  20.5,  24.5,  26.2,  24.4,  24.8,\n",
        "        29.6,  42.8,  21.9,  20.9,  44. ,  50. ,  36. ,  30.1,  33.8,\n",
        "        43.1,  48.8,  31. ,  36.5,  22.8,  30.7,  50. ,  43.5,  20.7,\n",
        "        21.1,  25.2,  24.4,  35.2,  32.4,  32. ,  33.2,  33.1,  29.1,\n",
        "        35.1,  45.4,  35.4,  46. ,  50. ,  32.2,  22. ,  20.1,  23.2,\n",
        "        22.3,  24.8,  28.5,  37.3,  27.9,  23.9,  21.7,  28.6,  27.1,\n",
        "        20.3,  22.5,  29. ,  24.8,  22. ,  26.4,  33.1,  36.1,  28.4,\n",
        "        33.4,  28.2,  22.8,  20.3,  16.1,  22.1,  19.4,  21.6,  23.8,\n",
        "        16.2,  17.8,  19.8,  23.1,  21. ,  23.8,  23.1,  20.4,  18.5,\n",
        "        25. ,  24.6,  23. ,  22.2,  19.3,  22.6,  19.8,  17.1,  19.4,\n",
        "        22.2,  20.7,  21.1,  19.5,  18.5,  20.6,  19. ,  18.7,  32.7,\n",
        "        16.5,  23.9,  31.2,  17.5,  17.2,  23.1,  24.5,  26.6,  22.9,\n",
        "        24.1,  18.6,  30.1,  18.2,  20.6,  17.8,  21.7,  22.7,  22.6,\n",
        "        25. ,  19.9,  20.8,  16.8,  21.9,  27.5,  21.9,  23.1,  50. ,\n",
        "        50. ,  50. ,  50. ,  50. ,  13.8,  13.8,  15. ,  13.9,  13.3,\n",
        "        13.1,  10.2,  10.4,  10.9,  11.3,  12.3,   8.8,   7.2,  10.5,\n",
        "         7.4,  10.2,  11.5,  15.1,  23.2,   9.7,  13.8,  12.7,  13.1,\n",
        "        12.5,   8.5,   5. ,   6.3,   5.6,   7.2,  12.1,   8.3,   8.5,\n",
        "         5. ,  11.9,  27.9,  17.2,  27.5,  15. ,  17.2,  17.9,  16.3,\n",
        "         7. ,   7.2,   7.5,  10.4,   8.8,   8.4,  16.7,  14.2,  20.8,\n",
        "        13.4,  11.7,   8.3,  10.2,  10.9,  11. ,   9.5,  14.5,  14.1,\n",
        "        16.1,  14.3,  11.7,  13.4,   9.6,   8.7,   8.4,  12.8,  10.5,\n",
        "        17.1,  18.4,  15.4,  10.8,  11.8,  14.9,  12.6,  14.1,  13. ,\n",
        "        13.4,  15.2,  16.1,  17.8,  14.9,  14.1,  12.7,  13.5,  14.9,\n",
        "        20. ,  16.4,  17.7,  19.5,  20.2,  21.4,  19.9,  19. ,  19.1,\n",
        "        19.1,  20.1,  19.9,  19.6,  23.2,  29.8,  13.8,  13.3,  16.7,\n",
        "        12. ,  14.6,  21.4,  23. ,  23.7,  25. ,  21.8,  20.6,  21.2,\n",
        "        19.1,  20.6,  15.2,   7. ,   8.1,  13.6,  20.1,  21.8,  24.5,\n",
        "        23.1,  19.7,  18.3,  21.2,  17.5,  16.8,  22.4,  20.6,  23.9,\n",
        "        22. ,  11.9])"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(slope,bias),total_error,_,_ = np.linalg.lstsq(x,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "slope"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "9.1021089811803098"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bias"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "-34.670620776438568"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(slope,bias),total_error,_,_ = np.linalg.lstsq(x,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total_error"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "array([ 22061.87919621])"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rmse = np.sqrt(total_error[0]/len(x))\n",
      "print('RMSE on training: {}'.format(rmse))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE on training: 6.60307138922\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 7.1.1 \u591a\u6b21\u5143\u56de\u5e30\n",
      "# all features + bias"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = boston.data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.array([np.concatenate( [ v,[1] ] ) for v in x])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "array([[  6.32000000e-03,   1.80000000e+01,   2.31000000e+00, ...,\n",
        "          3.96900000e+02,   4.98000000e+00,   1.00000000e+00],\n",
        "       [  2.73100000e-02,   0.00000000e+00,   7.07000000e+00, ...,\n",
        "          3.96900000e+02,   9.14000000e+00,   1.00000000e+00],\n",
        "       [  2.72900000e-02,   0.00000000e+00,   7.07000000e+00, ...,\n",
        "          3.92830000e+02,   4.03000000e+00,   1.00000000e+00],\n",
        "       ..., \n",
        "       [  6.07600000e-02,   0.00000000e+00,   1.19300000e+01, ...,\n",
        "          3.96900000e+02,   5.64000000e+00,   1.00000000e+00],\n",
        "       [  1.09590000e-01,   0.00000000e+00,   1.19300000e+01, ...,\n",
        "          3.93450000e+02,   6.48000000e+00,   1.00000000e+00],\n",
        "       [  4.74100000e-02,   0.00000000e+00,   1.19300000e+01, ...,\n",
        "          3.96900000e+02,   7.88000000e+00,   1.00000000e+00]])"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = boston.target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s,total_error,_,_ = np.linalg.lstsq(x,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rmse = np.sqrt(total_error[0]/len(x))\n",
      "print('RMSE on training: {}'.format(rmse))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE on training: 4.67950630064\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u307e\u3068\u3081\u308b\u3068\n",
      "x = boston.data\n",
      "# np.concatenate\u306f\u4e8c\u3064\u306e\u914d\u5217\u30fb\u30ea\u30b9\u30c8\u3092\u7d50\u5408\u3059\u308b\n",
      "# v\u306f\u8907\u6570\u306e\u8981\u7d20\u3092\u6301\u3064\u914d\u5217\u3066\u3099\u3042\u308b\u305f\u3081\u3001\n",
      "# \u3053\u3053\u3066\u3099\u306fnp.concatenate\u3092\u7528\u3044\u3066\u3001\u30cf\u3099\u30a4\u30a2\u30b9\u9805\u3092\u8ffd\u52a0\n",
      "x = np.array([np.concatenate( [ v,[1] ] ) for v in x]) #\u6559\u79d1\u66f8\u306e\u4f8b\u306f\u30ab\u30c3\u30b3\u304c\u8db3\u308a\u306a\u3044\n",
      "y = boston.target\n",
      "s,total_error,_,_ = np.linalg.lstsq(x,y)\n",
      "rmse = np.sqrt(total_error[0]/len(x))\n",
      "print('RMSE on training: {}'.format(rmse))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE on training: 4.67950630064\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#sklearn.linear_model.LinearRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LinearRegression\n",
      "lr = LinearRegression(fit_intercept=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 183
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr.fit(x,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 206,
       "text": [
        "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
       ]
      }
     ],
     "prompt_number": 206
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = map(lr.predict, x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 207
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 208,
       "text": [
        "[array([ 30.00821269]),\n",
        " array([ 25.0298606]),\n",
        " array([ 30.5702317]),\n",
        " array([ 28.60814055]),\n",
        " array([ 27.94288232]),\n",
        " array([ 25.25940048]),\n",
        " array([ 23.00433994]),\n",
        " array([ 19.5347558]),\n",
        " array([ 11.51696539]),\n",
        " array([ 18.91981483]),\n",
        " array([ 18.9958266]),\n",
        " array([ 21.58970854]),\n",
        " array([ 20.90534851]),\n",
        " array([ 19.55535931]),\n",
        " array([ 19.2837957]),\n",
        " array([ 19.30000174]),\n",
        " array([ 20.52889993]),\n",
        " array([ 16.9096749]),\n",
        " array([ 16.17067411]),\n",
        " array([ 18.40781636]),\n",
        " array([ 12.52040454]),\n",
        " array([ 17.67104565]),\n",
        " array([ 15.82934891]),\n",
        " array([ 13.80368317]),\n",
        " array([ 15.67708138]),\n",
        " array([ 13.3791645]),\n",
        " array([ 15.46258829]),\n",
        " array([ 14.69863607]),\n",
        " array([ 19.54518512]),\n",
        " array([ 20.87309945]),\n",
        " array([ 11.44806825]),\n",
        " array([ 18.05900412]),\n",
        " array([ 8.78841666]),\n",
        " array([ 14.27882319]),\n",
        " array([ 13.69097132]),\n",
        " array([ 23.81755469]),\n",
        " array([ 22.34216285]),\n",
        " array([ 23.11123204]),\n",
        " array([ 22.91494157]),\n",
        " array([ 31.35826216]),\n",
        " array([ 34.21485385]),\n",
        " array([ 28.0207132]),\n",
        " array([ 25.20646572]),\n",
        " array([ 24.61192851]),\n",
        " array([ 22.94438953]),\n",
        " array([ 22.10150945]),\n",
        " array([ 20.42467417]),\n",
        " array([ 18.03614022]),\n",
        " array([ 9.10176198]),\n",
        " array([ 17.20856571]),\n",
        " array([ 21.28259372]),\n",
        " array([ 23.97621248]),\n",
        " array([ 27.65853521]),\n",
        " array([ 24.0521088]),\n",
        " array([ 15.35989132]),\n",
        " array([ 31.14817003]),\n",
        " array([ 24.85878746]),\n",
        " array([ 33.11017111]),\n",
        " array([ 21.77458036]),\n",
        " array([ 21.08526739]),\n",
        " array([ 17.87203538]),\n",
        " array([ 18.50881381]),\n",
        " array([ 23.9879809]),\n",
        " array([ 22.54944098]),\n",
        " array([ 23.37068403]),\n",
        " array([ 30.36557584]),\n",
        " array([ 25.53407332]),\n",
        " array([ 21.11758504]),\n",
        " array([ 17.42468223]),\n",
        " array([ 20.7893086]),\n",
        " array([ 25.20349174]),\n",
        " array([ 21.74490595]),\n",
        " array([ 24.56275612]),\n",
        " array([ 24.04479519]),\n",
        " array([ 25.5091157]),\n",
        " array([ 23.97076758]),\n",
        " array([ 22.94823519]),\n",
        " array([ 23.36106095]),\n",
        " array([ 21.26432549]),\n",
        " array([ 22.4345376]),\n",
        " array([ 28.40699937]),\n",
        " array([ 26.99734716]),\n",
        " array([ 26.03807246]),\n",
        " array([ 25.06152125]),\n",
        " array([ 24.7858613]),\n",
        " array([ 27.79291889]),\n",
        " array([ 22.16927073]),\n",
        " array([ 25.89685664]),\n",
        " array([ 30.67771522]),\n",
        " array([ 30.83225886]),\n",
        " array([ 27.12127354]),\n",
        " array([ 27.41597825]),\n",
        " array([ 28.9456478]),\n",
        " array([ 29.08668003]),\n",
        " array([ 27.04501726]),\n",
        " array([ 28.62506705]),\n",
        " array([ 24.73038218]),\n",
        " array([ 35.78062378]),\n",
        " array([ 35.11269515]),\n",
        " array([ 32.25115468]),\n",
        " array([ 24.57946786]),\n",
        " array([ 25.59386215]),\n",
        " array([ 19.76439137]),\n",
        " array([ 20.31157117]),\n",
        " array([ 21.4353635]),\n",
        " array([ 18.53971968]),\n",
        " array([ 17.18572611]),\n",
        " array([ 20.74934949]),\n",
        " array([ 22.64791346]),\n",
        " array([ 19.77000977]),\n",
        " array([ 20.64745349]),\n",
        " array([ 26.52652691]),\n",
        " array([ 20.77440554]),\n",
        " array([ 20.71546432]),\n",
        " array([ 25.17461484]),\n",
        " array([ 20.4273652]),\n",
        " array([ 23.37862521]),\n",
        " array([ 23.69454145]),\n",
        " array([ 20.33202239]),\n",
        " array([ 20.79378139]),\n",
        " array([ 21.92024414]),\n",
        " array([ 22.47432006]),\n",
        " array([ 20.55884635]),\n",
        " array([ 16.36300764]),\n",
        " array([ 20.56342111]),\n",
        " array([ 22.48570454]),\n",
        " array([ 14.61264839]),\n",
        " array([ 15.1802607]),\n",
        " array([ 18.93828443]),\n",
        " array([ 14.0574955]),\n",
        " array([ 20.03651959]),\n",
        " array([ 19.41306288]),\n",
        " array([ 20.06401034]),\n",
        " array([ 15.76005772]),\n",
        " array([ 13.24771577]),\n",
        " array([ 17.26167729]),\n",
        " array([ 15.87759672]),\n",
        " array([ 19.36145104]),\n",
        " array([ 13.81270814]),\n",
        " array([ 16.44782934]),\n",
        " array([ 13.56511101]),\n",
        " array([ 3.98343974]),\n",
        " array([ 14.59241207]),\n",
        " array([ 12.14503093]),\n",
        " array([ 8.72407108]),\n",
        " array([ 12.00815659]),\n",
        " array([ 15.80308586]),\n",
        " array([ 8.50963929]),\n",
        " array([ 9.70965512]),\n",
        " array([ 14.79848067]),\n",
        " array([ 20.83598096]),\n",
        " array([ 18.30017013]),\n",
        " array([ 20.12575267]),\n",
        " array([ 17.27585681]),\n",
        " array([ 22.35997992]),\n",
        " array([ 20.07985184]),\n",
        " array([ 13.59903744]),\n",
        " array([ 33.26635221]),\n",
        " array([ 29.03938379]),\n",
        " array([ 25.56694529]),\n",
        " array([ 32.71732164]),\n",
        " array([ 36.78111388]),\n",
        " array([ 40.56615533]),\n",
        " array([ 41.85122271]),\n",
        " array([ 24.79875684]),\n",
        " array([ 25.3771545]),\n",
        " array([ 37.20662185]),\n",
        " array([ 23.08244608]),\n",
        " array([ 26.40326834]),\n",
        " array([ 26.65647433]),\n",
        " array([ 22.55412919]),\n",
        " array([ 24.2970948]),\n",
        " array([ 22.98024802]),\n",
        " array([ 29.07488389]),\n",
        " array([ 26.52620066]),\n",
        " array([ 30.72351225]),\n",
        " array([ 25.61835359]),\n",
        " array([ 29.14203283]),\n",
        " array([ 31.43690634]),\n",
        " array([ 32.9232938]),\n",
        " array([ 34.72096487]),\n",
        " array([ 27.76792733]),\n",
        " array([ 33.88992899]),\n",
        " array([ 30.99725805]),\n",
        " array([ 22.72124288]),\n",
        " array([ 24.76567683]),\n",
        " array([ 35.88131719]),\n",
        " array([ 33.42696242]),\n",
        " array([ 32.41513625]),\n",
        " array([ 34.51611818]),\n",
        " array([ 30.76057666]),\n",
        " array([ 30.29169893]),\n",
        " array([ 32.92040221]),\n",
        " array([ 32.11459912]),\n",
        " array([ 31.56133385]),\n",
        " array([ 40.84274603]),\n",
        " array([ 36.13046343]),\n",
        " array([ 32.66639271]),\n",
        " array([ 34.70558647]),\n",
        " array([ 30.09276228]),\n",
        " array([ 30.64139724]),\n",
        " array([ 29.29189704]),\n",
        " array([ 37.07062623]),\n",
        " array([ 42.02879611]),\n",
        " array([ 43.18582722]),\n",
        " array([ 22.6923888]),\n",
        " array([ 23.68420569]),\n",
        " array([ 17.85435295]),\n",
        " array([ 23.49543857]),\n",
        " array([ 17.00872418]),\n",
        " array([ 22.39535066]),\n",
        " array([ 17.06152243]),\n",
        " array([ 22.74106824]),\n",
        " array([ 25.21974252]),\n",
        " array([ 11.10601161]),\n",
        " array([ 24.51300617]),\n",
        " array([ 26.60749026]),\n",
        " array([ 28.35802444]),\n",
        " array([ 24.91860458]),\n",
        " array([ 29.69254951]),\n",
        " array([ 33.18492755]),\n",
        " array([ 23.77145523]),\n",
        " array([ 32.14086508]),\n",
        " array([ 29.74802362]),\n",
        " array([ 38.36605632]),\n",
        " array([ 39.80716458]),\n",
        " array([ 37.58362546]),\n",
        " array([ 32.39769704]),\n",
        " array([ 35.45048257]),\n",
        " array([ 31.23446481]),\n",
        " array([ 24.48478321]),\n",
        " array([ 33.28615723]),\n",
        " array([ 38.04368164]),\n",
        " array([ 37.15737267]),\n",
        " array([ 31.71297469]),\n",
        " array([ 25.26658017]),\n",
        " array([ 30.101515]),\n",
        " array([ 32.71897655]),\n",
        " array([ 28.42735376]),\n",
        " array([ 28.42999168]),\n",
        " array([ 27.2913215]),\n",
        " array([ 23.74446671]),\n",
        " array([ 24.11878941]),\n",
        " array([ 27.40241209]),\n",
        " array([ 16.32993575]),\n",
        " array([ 13.39695213]),\n",
        " array([ 20.01655581]),\n",
        " array([ 19.86205904]),\n",
        " array([ 21.28604604]),\n",
        " array([ 24.07796482]),\n",
        " array([ 24.20603792]),\n",
        " array([ 25.04201534]),\n",
        " array([ 24.91709097]),\n",
        " array([ 29.93762975]),\n",
        " array([ 23.97709054]),\n",
        " array([ 21.69931969]),\n",
        " array([ 37.51051381]),\n",
        " array([ 43.29459357]),\n",
        " array([ 36.48121427]),\n",
        " array([ 34.99129701]),\n",
        " array([ 34.80865729]),\n",
        " array([ 37.16296374]),\n",
        " array([ 40.9823638]),\n",
        " array([ 34.44211691]),\n",
        " array([ 35.83178068]),\n",
        " array([ 28.24913647]),\n",
        " array([ 31.22022312]),\n",
        " array([ 40.83256202]),\n",
        " array([ 39.31768808]),\n",
        " array([ 25.71099424]),\n",
        " array([ 22.30344878]),\n",
        " array([ 27.20551341]),\n",
        " array([ 28.51386352]),\n",
        " array([ 35.47494122]),\n",
        " array([ 36.11110647]),\n",
        " array([ 33.80004807]),\n",
        " array([ 35.61141951]),\n",
        " array([ 34.84311742]),\n",
        " array([ 30.35359323]),\n",
        " array([ 35.31260262]),\n",
        " array([ 38.79684808]),\n",
        " array([ 34.33296541]),\n",
        " array([ 40.34038636]),\n",
        " array([ 44.67339923]),\n",
        " array([ 31.5955473]),\n",
        " array([ 27.35994642]),\n",
        " array([ 20.09520596]),\n",
        " array([ 27.04518524]),\n",
        " array([ 27.21674397]),\n",
        " array([ 26.91105226]),\n",
        " array([ 33.43602979]),\n",
        " array([ 34.40228785]),\n",
        " array([ 31.83374181]),\n",
        " array([ 25.82416035]),\n",
        " array([ 24.43687139]),\n",
        " array([ 28.46348891]),\n",
        " array([ 27.36916176]),\n",
        " array([ 19.54441878]),\n",
        " array([ 29.11480679]),\n",
        " array([ 31.90852699]),\n",
        " array([ 30.77325183]),\n",
        " array([ 28.9430835]),\n",
        " array([ 28.88108106]),\n",
        " array([ 32.79876794]),\n",
        " array([ 33.20356949]),\n",
        " array([ 30.76568546]),\n",
        " array([ 35.55843485]),\n",
        " array([ 32.70725436]),\n",
        " array([ 28.64759861]),\n",
        " array([ 23.59388439]),\n",
        " array([ 18.5461558]),\n",
        " array([ 26.88429024]),\n",
        " array([ 23.28485442]),\n",
        " array([ 25.55002201]),\n",
        " array([ 25.48337323]),\n",
        " array([ 20.54343769]),\n",
        " array([ 17.61406384]),\n",
        " array([ 18.37627933]),\n",
        " array([ 24.29187594]),\n",
        " array([ 21.3257202]),\n",
        " array([ 24.88826131]),\n",
        " array([ 24.87143049]),\n",
        " array([ 22.87255605]),\n",
        " array([ 19.4540234]),\n",
        " array([ 25.11948741]),\n",
        " array([ 24.66816374]),\n",
        " array([ 23.68209656]),\n",
        " array([ 19.33951725]),\n",
        " array([ 21.17636041]),\n",
        " array([ 24.25306588]),\n",
        " array([ 21.59311197]),\n",
        " array([ 19.98766667]),\n",
        " array([ 23.34079584]),\n",
        " array([ 22.13973959]),\n",
        " array([ 21.55349196]),\n",
        " array([ 20.61808868]),\n",
        " array([ 20.1607571]),\n",
        " array([ 19.28455466]),\n",
        " array([ 22.16593919]),\n",
        " array([ 21.24893735]),\n",
        " array([ 21.42985456]),\n",
        " array([ 30.32874523]),\n",
        " array([ 22.04915396]),\n",
        " array([ 27.70610125]),\n",
        " array([ 28.54595004]),\n",
        " array([ 16.54657063]),\n",
        " array([ 14.78278261]),\n",
        " array([ 25.27336772]),\n",
        " array([ 27.54088054]),\n",
        " array([ 22.14633467]),\n",
        " array([ 20.46081206]),\n",
        " array([ 20.54472332]),\n",
        " array([ 16.88194391]),\n",
        " array([ 25.40066956]),\n",
        " array([ 14.32299547]),\n",
        " array([ 16.5927403]),\n",
        " array([ 19.63224597]),\n",
        " array([ 22.7117302]),\n",
        " array([ 22.19946949]),\n",
        " array([ 19.1989151]),\n",
        " array([ 22.66091019]),\n",
        " array([ 18.92059374]),\n",
        " array([ 18.22715359]),\n",
        " array([ 20.22444386]),\n",
        " array([ 37.47946099]),\n",
        " array([ 14.29172583]),\n",
        " array([ 15.53697148]),\n",
        " array([ 10.82825817]),\n",
        " array([ 23.81134987]),\n",
        " array([ 32.64787163]),\n",
        " array([ 34.61163401]),\n",
        " array([ 24.94604102]),\n",
        " array([ 26.00259724]),\n",
        " array([ 6.12085728]),\n",
        " array([ 0.78021126]),\n",
        " array([ 25.311373]),\n",
        " array([ 17.73465914]),\n",
        " array([ 20.22593282]),\n",
        " array([ 15.83834861]),\n",
        " array([ 16.83742401]),\n",
        " array([ 14.43123608]),\n",
        " array([ 18.47647773]),\n",
        " array([ 13.42427933]),\n",
        " array([ 13.05677824]),\n",
        " array([ 3.27646485]),\n",
        " array([ 8.05936467]),\n",
        " array([ 6.13903114]),\n",
        " array([ 5.62271213]),\n",
        " array([ 6.44935154]),\n",
        " array([ 14.20597451]),\n",
        " array([ 17.21022671]),\n",
        " array([ 17.29035065]),\n",
        " array([ 9.89064351]),\n",
        " array([ 20.21972222]),\n",
        " array([ 17.94511052]),\n",
        " array([ 20.30017588]),\n",
        " array([ 19.28790318]),\n",
        " array([ 16.33300008]),\n",
        " array([ 6.56843662]),\n",
        " array([ 10.87541577]),\n",
        " array([ 11.88704097]),\n",
        " array([ 17.81098929]),\n",
        " array([ 18.25461066]),\n",
        " array([ 12.99282707]),\n",
        " array([ 7.39319053]),\n",
        " array([ 8.25609561]),\n",
        " array([ 8.07899971]),\n",
        " array([ 19.98563715]),\n",
        " array([ 13.69651744]),\n",
        " array([ 19.83511412]),\n",
        " array([ 15.2345378]),\n",
        " array([ 16.93112419]),\n",
        " array([ 1.69347406]),\n",
        " array([ 11.81116263]),\n",
        " array([-4.28300934]),\n",
        " array([ 9.55007844]),\n",
        " array([ 13.32635521]),\n",
        " array([ 6.88351077]),\n",
        " array([ 6.16827417]),\n",
        " array([ 14.56933235]),\n",
        " array([ 19.59292932]),\n",
        " array([ 18.1151686]),\n",
        " array([ 18.52011987]),\n",
        " array([ 13.13707457]),\n",
        " array([ 14.59662601]),\n",
        " array([ 9.8923749]),\n",
        " array([ 16.31998048]),\n",
        " array([ 14.06750301]),\n",
        " array([ 14.22573568]),\n",
        " array([ 13.00752251]),\n",
        " array([ 18.13277547]),\n",
        " array([ 18.66645496]),\n",
        " array([ 21.50283795]),\n",
        " array([ 17.00039379]),\n",
        " array([ 15.93926602]),\n",
        " array([ 13.32952716]),\n",
        " array([ 14.48949211]),\n",
        " array([ 8.78366731]),\n",
        " array([ 4.8300317]),\n",
        " array([ 13.06115528]),\n",
        " array([ 12.71101472]),\n",
        " array([ 17.2887624]),\n",
        " array([ 18.73424906]),\n",
        " array([ 18.05271013]),\n",
        " array([ 11.49855612]),\n",
        " array([ 13.00841512]),\n",
        " array([ 17.66975577]),\n",
        " array([ 18.12342294]),\n",
        " array([ 17.51503231]),\n",
        " array([ 17.21307203]),\n",
        " array([ 16.48238543]),\n",
        " array([ 19.40079737]),\n",
        " array([ 18.57392951]),\n",
        " array([ 22.47833186]),\n",
        " array([ 15.24179836]),\n",
        " array([ 15.78327609]),\n",
        " array([ 12.64853778]),\n",
        " array([ 12.84121049]),\n",
        " array([ 17.17173661]),\n",
        " array([ 18.50906858]),\n",
        " array([ 19.02803874]),\n",
        " array([ 20.16441773]),\n",
        " array([ 19.76975335]),\n",
        " array([ 22.42614937]),\n",
        " array([ 20.31750314]),\n",
        " array([ 17.87618837]),\n",
        " array([ 14.3391341]),\n",
        " array([ 16.93715603]),\n",
        " array([ 16.98716629]),\n",
        " array([ 18.59431701]),\n",
        " array([ 20.16395155]),\n",
        " array([ 22.97743546]),\n",
        " array([ 22.45110639]),\n",
        " array([ 25.5707207]),\n",
        " array([ 16.39091112]),\n",
        " array([ 16.09765427]),\n",
        " array([ 20.52835689]),\n",
        " array([ 11.5429045]),\n",
        " array([ 19.20387482]),\n",
        " array([ 21.86820603]),\n",
        " array([ 23.47052203]),\n",
        " array([ 27.10034494]),\n",
        " array([ 28.57064813]),\n",
        " array([ 21.0839881]),\n",
        " array([ 19.4490529]),\n",
        " array([ 22.2189221]),\n",
        " array([ 19.65423066]),\n",
        " array([ 21.324671]),\n",
        " array([ 11.86231364]),\n",
        " array([ 8.22260592]),\n",
        " array([ 3.65825168]),\n",
        " array([ 13.76275951]),\n",
        " array([ 15.93780944]),\n",
        " array([ 20.62730097]),\n",
        " array([ 20.61035443]),\n",
        " array([ 16.88048035]),\n",
        " array([ 14.01017244]),\n",
        " array([ 19.10825534]),\n",
        " array([ 21.29720741]),\n",
        " array([ 18.45524217]),\n",
        " array([ 20.46764235]),\n",
        " array([ 23.53261729]),\n",
        " array([ 22.37869798]),\n",
        " array([ 27.62934247]),\n",
        " array([ 26.12983844]),\n",
        " array([ 22.34870269])]"
       ]
      }
     ],
     "prompt_number": 208
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = [v[0] for v in p] #\u6559\u79d1\u66f8\u306c\u3051\u3066\u308b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e = p-y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 188,
       "text": [
        "array([  6.00821269e+00,   3.42986060e+00,  -4.12976830e+00,\n",
        "        -4.79185945e+00,  -8.25711768e+00,  -3.44059952e+00,\n",
        "         1.04339941e-01,  -7.56524420e+00,  -4.98303461e+00,\n",
        "         1.98148310e-02,   3.99582660e+00,   2.68970854e+00,\n",
        "        -7.94651488e-01,  -8.44640693e-01,   1.08379570e+00,\n",
        "        -5.99998256e-01,  -2.57110007e+00,  -5.90325101e-01,\n",
        "        -4.02932589e+00,   2.07816357e-01,  -1.07959546e+00,\n",
        "        -1.92895435e+00,   6.29348907e-01,  -6.96316828e-01,\n",
        "         7.70813834e-02,  -5.20835501e-01,  -1.13741171e+00,\n",
        "        -1.01363929e-01,   1.14518512e+00,  -1.26900546e-01,\n",
        "        -1.25193175e+00,   3.55900412e+00,  -4.41158334e+00,\n",
        "         1.17882319e+00,   1.90971317e-01,   4.91755469e+00,\n",
        "         2.34216285e+00,   2.11123204e+00,  -1.78505843e+00,\n",
        "         5.58262157e-01,  -6.85146149e-01,   1.42071320e+00,\n",
        "        -9.35342804e-02,  -8.80714949e-02,   1.74438953e+00,\n",
        "         2.80150945e+00,   4.24674174e-01,   1.43614022e+00,\n",
        "        -5.29823802e+00,  -2.19143429e+00,   1.58259372e+00,\n",
        "         3.47621248e+00,   2.65853521e+00,   6.52108797e-01,\n",
        "        -3.54010868e+00,  -4.25182997e+00,   1.58787464e-01,\n",
        "         1.51017111e+00,  -1.52541964e+00,   1.48526739e+00,\n",
        "        -8.27964625e-01,   2.50881381e+00,   1.78798090e+00,\n",
        "        -2.45055902e+00,  -9.62931597e+00,   6.86557584e+00,\n",
        "         6.13407332e+00,  -8.82414962e-01,   2.46822319e-02,\n",
        "        -1.10691396e-01,   1.00349174e+00,   4.49059486e-02,\n",
        "         1.76275612e+00,   6.44795192e-01,   1.40911570e+00,\n",
        "         2.57076758e+00,   2.94823519e+00,   2.56106095e+00,\n",
        "         6.43254889e-02,   2.13453760e+00,   4.06999367e-01,\n",
        "         3.09734716e+00,   1.23807246e+00,   2.16152125e+00,\n",
        "         8.85861304e-01,   1.19291889e+00,  -3.30729274e-01,\n",
        "         3.69685664e+00,   7.07771522e+00,   2.13225886e+00,\n",
        "         4.52127354e+00,   5.41597825e+00,   6.04564780e+00,\n",
        "         4.08668003e+00,   6.44501726e+00,   2.25067052e-01,\n",
        "         3.33038218e+00,  -2.91937622e+00,  -8.68730485e+00,\n",
        "        -9.48845321e-01,  -2.92053214e+00,  -9.06137851e-01,\n",
        "         1.16439137e+00,   1.01157117e+00,   1.33536350e+00,\n",
        "        -9.60280317e-01,  -2.31427389e+00,   3.49349494e-01,\n",
        "         2.84791346e+00,   3.70009771e-01,  -1.05254651e+00,\n",
        "         3.72652691e+00,   1.97440554e+00,   2.01546432e+00,\n",
        "         6.67461484e+00,   2.12736520e+00,   2.17862521e+00,\n",
        "         4.49454145e+00,  -6.79776135e-02,   1.49378139e+00,\n",
        "        -7.97558587e-02,   2.17432006e+00,   5.88463520e-02,\n",
        "        -9.36992356e-01,   1.76342111e+00,   1.08570454e+00,\n",
        "        -1.08735161e+00,  -1.01973930e+00,   9.38284433e-01,\n",
        "        -2.42504502e-01,   8.36519590e-01,  -1.86937120e-01,\n",
        "        -2.93598966e+00,  -2.63994228e+00,  -2.35228423e+00,\n",
        "        -8.38322710e-01,  -1.52240328e+00,   2.26145104e+00,\n",
        "         5.12708138e-01,  -1.35217066e+00,  -4.34888989e-01,\n",
        "        -1.04165603e+01,   1.19241207e+00,  -3.45496907e+00,\n",
        "        -3.07592892e+00,  -1.79184341e+00,   2.03085863e-01,\n",
        "        -6.09036071e+00,  -8.09034488e+00,  -6.01519327e-01,\n",
        "        -6.64019038e-01,  -1.29982987e+00,   4.82575267e+00,\n",
        "        -2.12414319e+00,   5.35997992e+00,   4.47985184e+00,\n",
        "         4.99037441e-01,  -8.03364779e+00,   4.73938379e+00,\n",
        "         2.26694529e+00,   5.71732164e+00,  -1.32188861e+01,\n",
        "        -9.43384467e+00,  -8.14877729e+00,   2.09875684e+00,\n",
        "         3.77154499e-01,  -1.27933781e+01,  -7.17553923e-01,\n",
        "         2.60326834e+00,   4.35647433e+00,   5.15412919e+00,\n",
        "         5.19709480e+00,  -1.19751980e-01,   5.47488389e+00,\n",
        "         3.92620066e+00,   1.32351225e+00,   2.41835359e+00,\n",
        "         4.54203283e+00,   1.53690634e+00,  -4.27670620e+00,\n",
        "        -5.07903513e+00,  -8.43207267e+00,  -4.01007101e+00,\n",
        "        -1.50274195e+00,  -3.67875712e+00,  -4.83432317e+00,\n",
        "        -1.41186828e+01,   1.42696242e+00,   2.61513625e+00,\n",
        "        -3.83881817e-01,  -6.23942334e+00,  -2.08301073e-01,\n",
        "        -3.47959779e+00,   1.01459912e+00,   2.46133385e+00,\n",
        "        -9.15725397e+00,   2.83046343e+00,   2.36639271e+00,\n",
        "         1.05586470e-01,  -4.80723772e+00,  -2.25860276e+00,\n",
        "         5.19189704e+00,  -5.22937377e+00,  -6.47120389e+00,\n",
        "        -6.81417278e+00,   9.23887977e-02,  -7.15794308e-01,\n",
        "        -4.64564705e+00,  -9.04561434e-01,  -2.99127582e+00,\n",
        "         6.95350660e-01,  -2.23847757e+00,   3.41068242e-01,\n",
        "        -2.88025748e+00,  -1.25939884e+01,  -4.86993833e-01,\n",
        "         3.30749026e+00,  -3.41975565e-01,   3.41860458e+00,\n",
        "         6.69254951e+00,   6.48492755e+00,   2.07145523e+00,\n",
        "         4.64086508e+00,  -3.51976378e-01,  -6.43394368e+00,\n",
        "        -1.01928354e+01,  -1.63745433e-02,   7.97697035e-01,\n",
        "        -1.12495174e+01,  -2.65535193e-01,   1.84783212e-01,\n",
        "         1.58615723e+00,  -3.65631836e+00,  -1.11426273e+01,\n",
        "         2.71297469e+00,   1.26658017e+00,   5.00151500e+00,\n",
        "         1.21897655e+00,   4.72735376e+00,   5.12999168e+00,\n",
        "         5.29132150e+00,   3.64446671e+00,   1.91878941e+00,\n",
        "         3.70241209e+00,  -1.27006425e+00,  -5.10304787e+00,\n",
        "        -4.28344419e+00,  -6.37940962e-01,  -3.21395396e+00,\n",
        "        -2.12203518e+00,  -1.93962076e-01,   2.42015338e-01,\n",
        "        -4.68290903e+00,  -1.28623702e+01,   2.07709054e+00,\n",
        "         7.99319690e-01,  -6.48948619e+00,  -6.70540643e+00,\n",
        "         4.81214265e-01,   4.89129701e+00,   1.00865729e+00,\n",
        "        -5.93703626e+00,  -7.81763620e+00,   3.44211691e+00,\n",
        "        -6.68219322e-01,   5.44913647e+00,   5.20223118e-01,\n",
        "        -9.16743798e+00,  -4.18231192e+00,   5.01099424e+00,\n",
        "         1.20344878e+00,   2.00551341e+00,   4.11386352e+00,\n",
        "         2.74941223e-01,   3.71110647e+00,   1.80004807e+00,\n",
        "         2.41141951e+00,   1.74311742e+00,   1.25359323e+00,\n",
        "         2.12602620e-01,  -6.60315192e+00,  -1.06703459e+00,\n",
        "        -5.65961364e+00,  -5.32660077e+00,  -6.04452704e-01,\n",
        "         5.35994642e+00,  -4.79403771e-03,   3.84518524e+00,\n",
        "         4.91674397e+00,   2.11105226e+00,   4.93602979e+00,\n",
        "        -2.89771215e+00,   3.93374181e+00,   1.92416035e+00,\n",
        "         2.73687139e+00,  -1.36511091e-01,   2.69161758e-01,\n",
        "        -7.55581223e-01,   6.61480679e+00,   2.90852699e+00,\n",
        "         5.97325183e+00,   6.94308350e+00,   2.48108106e+00,\n",
        "        -3.01232056e-01,  -2.89643051e+00,   2.36568546e+00,\n",
        "         2.15843485e+00,   4.50725436e+00,   5.84759861e+00,\n",
        "         3.29388439e+00,   2.44615580e+00,   4.78429024e+00,\n",
        "         3.88485442e+00,   3.95002201e+00,   1.68337323e+00,\n",
        "         4.34343769e+00,  -1.85936163e-01,  -1.42372067e+00,\n",
        "         1.19187594e+00,   3.25720195e-01,   1.08826131e+00,\n",
        "         1.77143049e+00,   2.47255605e+00,   9.54023399e-01,\n",
        "         1.19487412e-01,   6.81637420e-02,   6.82096563e-01,\n",
        "        -2.86048275e+00,   1.87636041e+00,   1.65306588e+00,\n",
        "         1.79311197e+00,   2.88766667e+00,   3.94079584e+00,\n",
        "        -6.02604148e-02,   8.53491963e-01,  -4.81911321e-01,\n",
        "         6.60757096e-01,   7.84554664e-01,   1.56593919e+00,\n",
        "         2.24893735e+00,   2.72985456e+00,  -2.37125477e+00,\n",
        "         5.54915396e+00,   3.80610125e+00,  -2.65404996e+00,\n",
        "        -9.53429369e-01,  -2.41721739e+00,   2.17336772e+00,\n",
        "         3.04088054e+00,  -4.45366533e+00,  -2.43918794e+00,\n",
        "        -3.55527668e+00,  -1.71805609e+00,  -4.69933044e+00,\n",
        "        -3.87700453e+00,  -4.00725970e+00,   1.83224597e+00,\n",
        "         1.01173020e+00,  -5.00530508e-01,  -3.40108490e+00,\n",
        "        -2.33908981e+00,  -9.79406257e-01,  -2.57284641e+00,\n",
        "         3.42444386e+00,   1.55794610e+01,  -1.32082742e+01,\n",
        "        -6.36302852e+00,  -1.22717418e+01,  -2.61886501e+01,\n",
        "        -1.73521284e+01,  -1.53883660e+01,  -2.50539590e+01,\n",
        "        -2.39974028e+01,  -7.67914272e+00,  -1.30197887e+01,\n",
        "         1.03113730e+01,   3.83465914e+00,   6.92593282e+00,\n",
        "         2.73834861e+00,   6.63742401e+00,   4.03123608e+00,\n",
        "         7.57647773e+00,   2.12427933e+00,   7.56778235e-01,\n",
        "        -5.52353515e+00,   8.59364673e-01,  -4.36096886e+00,\n",
        "        -1.77728787e+00,  -3.75064846e+00,   2.70597451e+00,\n",
        "         2.11022671e+00,  -5.90964935e+00,   1.90643515e-01,\n",
        "         6.41972222e+00,   5.24511052e+00,   7.20017588e+00,\n",
        "         6.78790318e+00,   7.83300008e+00,   1.56843662e+00,\n",
        "         4.57541577e+00,   6.28704097e+00,   1.06109893e+01,\n",
        "         6.15461066e+00,   4.69282707e+00,  -1.10680947e+00,\n",
        "         3.25609561e+00,  -3.82100029e+00,  -7.91436285e+00,\n",
        "        -3.50348256e+00,  -7.66488588e+00,   2.34537805e-01,\n",
        "        -2.68875810e-01,  -1.62065259e+01,  -4.48883737e+00,\n",
        "        -1.12830093e+01,   2.35007844e+00,   5.82635521e+00,\n",
        "        -3.51648923e+00,  -2.63172583e+00,   6.16933235e+00,\n",
        "         2.89292932e+00,   3.91516860e+00,  -2.27988013e+00,\n",
        "        -2.62925428e-01,   2.89662601e+00,   1.59237490e+00,\n",
        "         6.11998048e+00,   3.16750301e+00,   3.22573568e+00,\n",
        "         3.50752251e+00,   3.63277547e+00,   4.56645496e+00,\n",
        "         5.40283795e+00,   2.70039379e+00,   4.23926602e+00,\n",
        "        -7.04728399e-02,   4.88949211e+00,   8.36673082e-02,\n",
        "        -3.56996830e+00,   2.61155281e-01,   2.21101472e+00,\n",
        "         1.88762404e-01,   3.34249061e-01,   2.65271013e+00,\n",
        "         6.98556119e-01,   1.20841512e+00,   2.76975577e+00,\n",
        "         5.52342294e+00,   3.41503231e+00,   4.21307203e+00,\n",
        "         3.08238543e+00,   4.20079737e+00,   2.47392951e+00,\n",
        "         4.67833186e+00,   3.41798355e-01,   1.68327609e+00,\n",
        "        -5.14622246e-02,  -6.58789511e-01,   2.27173661e+00,\n",
        "        -1.49093142e+00,   2.62803874e+00,   2.46441773e+00,\n",
        "         2.69753352e-01,   2.22614937e+00,  -1.08249686e+00,\n",
        "        -2.02381163e+00,  -4.66086590e+00,  -2.16284397e+00,\n",
        "        -2.11283371e+00,  -1.50568299e+00,   2.63951546e-01,\n",
        "         3.37743546e+00,  -7.48893611e-01,  -4.22927930e+00,\n",
        "         2.59091112e+00,   2.79765427e+00,   3.82835689e+00,\n",
        "        -4.57095495e-01,   4.60387482e+00,   4.68206028e-01,\n",
        "         4.70522032e-01,   3.40034494e+00,   3.57064813e+00,\n",
        "        -7.16011898e-01,  -1.15094710e+00,   1.01892210e+00,\n",
        "         5.54230662e-01,   7.24670996e-01,  -3.33768636e+00,\n",
        "         1.22260592e+00,  -4.44174832e+00,   1.62759507e-01,\n",
        "        -4.16219056e+00,  -1.17269903e+00,  -3.88964557e+00,\n",
        "        -6.21951965e+00,  -5.68982756e+00,   8.08255342e-01,\n",
        "         9.72074095e-02,   9.55242174e-01,   3.66764235e+00,\n",
        "         1.13261729e+00,   1.77869798e+00,   3.72934247e+00,\n",
        "         4.12983844e+00,   1.04487027e+01])"
       ]
      }
     ],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total_error = np.sum(e*e)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total_error"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 190,
       "text": [
        "11080.276284149873"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rmse_train = np.sqrt(total_error/len(p))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 191
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('RMSE on training: {}'.format(rmse_train))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE on training: 4.67950630064\n"
       ]
      }
     ],
     "prompt_number": 192
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u307e\u3068\u3081\u308b\u3068\n",
      "lr.fit(x,y)\n",
      "p = map(lr.predict, x)\n",
      "p = [v[0] for v in p] #\u3053\u308c\u304c\u306a\u3044\u3068\u304a\u304b\u3057\u3044\u5024\u306b\u306a\u308b\u3001\u6559\u79d1\u66f8\u306b\u306f\u306a\u3044\uff08\u4eca\u56de\u306f\u51fa\u529b\u304c\uff11\u3064\u306e\u307f\u306a\u306e\u3067\u3053\u308c\u306e0\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308c\u3070\u53d6\u308c\u308b\uff09\n",
      "e = p-y\n",
      "total_error = np.sum(e*e) \n",
      "rmse_train = np.sqrt(total_error/len(p))\n",
      "print('RMSE on training: {}'.format(rmse_train))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE on training: 4.67950630064\n"
       ]
      }
     ],
     "prompt_number": 343
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " #10 - fold cross validation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import KFold\n",
      "kf = KFold(len(x), n_folds=10)\n",
      "kf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'x' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-2-7e14d088c889>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "err = 0\n",
      "for train, test in kf:\n",
      "    lr.fit(x[train],y[train])\n",
      "    p = map(lr.predict, x[test])\n",
      "    p = [v[0] for v in p]\n",
      "    e = p-y[test]\n",
      "    err += np.sum(e*e)\n",
      "rmse_10cv = np.sqrt(err/len(x))\n",
      "print('RMSE on 10-fold CV: {}'.format(rmse_10cv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE on 10-fold CV: 5.88192507243\n"
       ]
      }
     ],
     "prompt_number": 339
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#7.2.2 Lasso, ElasticNet"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 281
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ElasticNet\n",
      "from sklearn.linear_model import ElasticNet\n",
      "en = ElasticNet(fit_intercept=True, alpha=0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 335
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u8a13\u7df4\u8aa4\u5dee\n",
      "en.fit(x,y)\n",
      "p = map(en.predict, x)\n",
      "p = [v[0] for v in p]\n",
      "e = p-y\n",
      "total_error = np.sum(e*e)\n",
      "rmse_train = np.sqrt(total_error/len(p))\n",
      "print('RMSE on training: {}'.format(rmse_train))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE on training: 4.98547427243\n"
       ]
      }
     ],
     "prompt_number": 341
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u4ea4\u5dee\u691c\u5b9a\n",
      "err = 0\n",
      "for train, test in kf:\n",
      "    en.fit(x[train],y[train]) \n",
      "    p = map(en.predict, x[test])\n",
      "    p = [v[0] for v in p]\n",
      "    e = p-y[test]\n",
      "    err += np.sum(e*e)\n",
      "rmse_10cv = np.sqrt(err/len(x))\n",
      "print('RMSE on 10-fold CV: {}'.format(rmse_10cv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE on 10-fold CV: 5.47790646659\n"
       ]
      }
     ],
     "prompt_number": 340
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#7.3.1 \u30c6\u30ad\u30b9\u30c8\u306b\u57fa\u3065\u3044\u305f\u30b5\u30f3\u30d7\u30eb\u30c7\u30fc\u30bf\n",
      "#\u30c7\u30fc\u30bf 180MB\n",
      "#curl -O http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression/E2006.train.bz2\n",
      "#bunzip2 E2006.train.bz2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 323
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\n",
      "#http://localhost:8888/notebooks/ML/Machine_Learning_Python_chap7/ML_chap7.ipynb\n",
      "from sklearn.datasets import load_svmlight_file\n",
      "data,target = load_svmlight_file('E2006.train')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#target\u306e\u8981\u7d20\u78ba\u8a8d\n",
      "print('Min target value: {}'.format(target.min()))\n",
      "print('Max target value: {}'.format(target.max()))\n",
      "print('Mean target value: {}'.format(target.mean()))\n",
      "print('Std. dev. target: {}'.format(target.std()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Min target value: -7.89957807347\n",
        "Max target value: -0.51940952694\n",
        "Mean target value: -3.51405313669\n",
        "Std. dev. target: 0.632278353911\n"
       ]
      }
     ],
     "prompt_number": 348
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LinearRegression\n",
      "lr = LinearRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 375
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u8a13\u7df4\u8aa4\u5dee\u306e\u5c0e\u51fa\n",
      "lr.fit(data,target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 359,
       "text": [
        "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
       ]
      }
     ],
     "prompt_number": 359
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# p\u306f\u30b5\u30a4\u30b9\u3099\u306f(1,16087)\u306e\u4e8c\u6b21\u5143\u914d\u5217\n",
      "p = np.array(map(lr.predict, data))\n",
      "p"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 354,
       "text": [
        "array([[-3.58958389],\n",
        "       [-3.52625643],\n",
        "       [-3.69048942],\n",
        "       ..., \n",
        "       [-3.45815738],\n",
        "       [-3.76216531],\n",
        "       [-3.62751994]])"
       ]
      }
     ],
     "prompt_number": 354
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ravel\u3092\u7528\u3044\u3066\u3001\u4e00\u6b21\u5143\u306e\u5e73\u3089\u306a\u914d\u5217\u306b\u3059\u308b\n",
      "p = p.ravel()\n",
      "p"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 355,
       "text": [
        "array([-3.58958389, -3.52625643, -3.69048942, ..., -3.45815738,\n",
        "       -3.76216531, -3.62751994])"
       ]
      }
     ],
     "prompt_number": 355
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \u8aa4\u5dee(\u5b9f\u969b\u306e\u5024\u3068\u4e88\u6e2c\u5024\u306e\u5dee)\u3092\u6c42\u3081\u308b\n",
      "e = p-target\n",
      "e"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 357,
       "text": [
        "array([-0.00014425,  0.00038174, -0.00060947, ...,  0.00018194,\n",
        "        0.0005803 , -0.00024346])"
       ]
      }
     ],
     "prompt_number": 357
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total_sq_error = np.sum(e*e)\n",
      "rmse_train = np.sqrt(total_sq_error/len(p))\n",
      "print(rmse_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.00237866684485\n"
       ]
      }
     ],
     "prompt_number": 358
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u307e\u3068\u3081\u308b\u3068\n",
      "from sklearn.linear_model import LinearRegression\n",
      "lr = LinearRegression()\n",
      "#\u8a13\u7df4\u8aa4\u5dee\n",
      "lr.fit(data,target)\n",
      "p = np.array(map(lr.predict, data))\n",
      "p = p.ravel()\n",
      "e = p-target\n",
      "total_sq_error = np.sum(e*e)\n",
      "rmse_train = np.sqrt(total_sq_error/len(p))\n",
      "print('RMSE on training: {}'.format(rmse_train))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE on training: 0.00237866684485\n"
       ]
      }
     ],
     "prompt_number": 376
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u5225\u306e\u8aa4\u5dee\u306e\u51fa\u529b\u6cd5\n",
      "from sklearn.metrics import mean_squared_error\n",
      "from sklearn.datasets import load_svmlight_file\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.cross_validation import KFold\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u8a13\u7df4\u8aa4\u5dee\n",
      "lr = LinearRegression()\n",
      "lr.fit(data, target)\n",
      "pred = lr.predict(data)\n",
      "print('RMSE on training, {:.2}'.format(np.sqrt(mean_squared_error(target, pred))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE on training, 0.0024\n"
       ]
      }
     ],
     "prompt_number": 390
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u4ea4\u5dee\u691c\u5b9a\n",
      "lr = LinearRegression()\n",
      "pred = np.zeros_like(target)\n",
      "kf = KFold(len(target), n_folds=5)\n",
      "for train, test in kf:\n",
      "    lr.fit(data[train], target[train])\n",
      "    pred[test] = lr.predict(data[test])\n",
      "\n",
      "print('RMSE on testing (5 fold), {:.2}'.format(np.sqrt(mean_squared_error(target, pred))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE on testing (5 fold), 0.75\n"
       ]
      }
     ],
     "prompt_number": 391
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#elastic net\n",
      "#\u4ea4\u5dee\u691c\u5b9a\n",
      "from sklearn.linear_model import ElasticNet\n",
      "met = ElasticNet(alpha=0.1)\n",
      "\n",
      "kf = KFold(len(target), n_folds=5)\n",
      "pred = np.zeros_like(target)\n",
      "for train, test in kf:\n",
      "    met.fit(data[train], target[train])\n",
      "    pred[test] = met.predict(data[test])\n",
      "    \n",
      "print('[EN 0.1] RMSE on testing (5 fold), {:.2}'.format(np.sqrt(mean_squared_error(target, pred))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[EN 0.1] RMSE on testing (5 fold), 0.4\n"
       ]
      }
     ],
     "prompt_number": 393
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u4e8c\u6bb5\u968e\u306e\u4ea4\u5dee\u691c\u5b9a\n",
      "#ElasticNetCV\n",
      "from sklearn.cross_validation import KFold\n",
      "from sklearn.linear_model import ElasticNetCV\n",
      "met = ElasticNetCV(n_jobs=-1)\n",
      "\n",
      "kf = KFold(len(target), n_folds=5)\n",
      "pred = np.zeros_like(target)\n",
      "for train, test in kf:\n",
      "    met.fit(data[train], target[train])\n",
      "    pred[test] = met.predict(data[test])\n",
      "\n",
      "print('[EN CV] RMSE on testing (5 fold), {:.2}'.format(np.sqrt(mean_squared_error(target, pred))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[EN CV] RMSE on testing (5 fold), 0.37\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}